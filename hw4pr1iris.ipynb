{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# hw4pr1iris:  iris clasification via nearest neighbors\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I predict setosa (0) from Features [4.6, 3.6, 3.0, 0.2]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# We don't need any data at all to create a predictive model!\n",
    "#\n",
    "import random\n",
    "\n",
    "def predictive_model( Features ):\n",
    "    \"\"\" input: a list of four features \n",
    "                [ sepallen, sepalwid, petallen, petalwid ]\n",
    "        output: the predicted species of iris, from\n",
    "                  setosa (0), versicolor (1), virginica (2)\n",
    "    \"\"\"\n",
    "    [ sepallen, sepalwid, petallen, petalwid ] = Features # unpacking!\n",
    "    if petalwid < 1.0:\n",
    "        return 'setosa (0)'\n",
    "    else:\n",
    "        return random.choice( ['versicolor (1)', 'virginica (2)'] )\n",
    "    \n",
    "#\n",
    "# Try it!\n",
    "# \n",
    "# Features = eval(input(\"Enter new Features: \"))\n",
    "#\n",
    "Features = [ 4.6, 3.6, 3.0, 0.2 ] \n",
    "result = predictive_model( Features )\n",
    "print(f\"I predict {result} from Features {Features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# (now, to explore how we _can_ use data to do better... :-) \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries!\n",
    "import numpy as np      # numpy is Python's \"array\" library\n",
    "import pandas as pd     # Pandas is Python's \"data\" library (\"dataframe\" == spreadsheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris.csv : file read into a pandas dataframe.\n"
     ]
    }
   ],
   "source": [
    "# let's read in our flower data...\n",
    "# \n",
    "# for read_csv, use header=0 when row 0 is a header row\n",
    "# \n",
    "filename = 'iris.csv'\n",
    "df = pd.read_csv(filename, header=0)   # encoding=\"latin1\" et al.\n",
    "print(f\"{filename} : file read into a pandas dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallen</th>\n",
       "      <th>sepalwid</th>\n",
       "      <th>petallen</th>\n",
       "      <th>petalwid</th>\n",
       "      <th>irisname</th>\n",
       "      <th>adapted from https://en.wikipedia.org/wiki/Iris_flower_data_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.200000e+00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.300000e+00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>4.2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4242.0</td>\n",
       "      <td>4.200000e+42</td>\n",
       "      <td>alieniris</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>4.2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4242.0</td>\n",
       "      <td>4.200000e+42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepallen  sepalwid  petallen      petalwid   irisname  \\\n",
       "0         4.6       3.6       1.0  2.000000e-01     setosa   \n",
       "1         4.3       3.0       1.1  1.000000e-01     setosa   \n",
       "2         5.0       3.2       1.2  2.000000e-01     setosa   \n",
       "3         5.8       4.0       1.2  2.000000e-01     setosa   \n",
       "4         4.4       3.0       1.3  2.000000e-01     setosa   \n",
       "..        ...       ...       ...           ...        ...   \n",
       "138       7.7       3.8       6.7  2.200000e+00  virginica   \n",
       "139       7.7       2.8       6.7  2.000000e+00  virginica   \n",
       "140       7.7       2.6       6.9  2.300000e+00  virginica   \n",
       "141       4.2      42.0    4242.0  4.200000e+42  alieniris   \n",
       "142       4.2      42.0    4242.0  4.200000e+42        NaN   \n",
       "\n",
       "     adapted from https://en.wikipedia.org/wiki/Iris_flower_data_set  \n",
       "0                                                  NaN                \n",
       "1                                                  NaN                \n",
       "2                                                  NaN                \n",
       "3                                                  NaN                \n",
       "4                                                  NaN                \n",
       "..                                                 ...                \n",
       "138                                                NaN                \n",
       "139                                                NaN                \n",
       "140                                                NaN                \n",
       "141                                                NaN                \n",
       "142                                                NaN                \n",
       "\n",
       "[143 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# a dataframe is a \"spreadsheet in Python\"   (seems to have an extra column!)\n",
    "#\n",
    "pd.set_option('display.max_rows', 10)  # None for no limit; default: 10\n",
    "pd.set_option('display.min_rows', 10)  # None for no limit; default: 10\n",
    "# let's view it!\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143 entries, 0 to 142\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                                           Non-Null Count  Dtype  \n",
      "---  ------                                                           --------------  -----  \n",
      " 0   sepallen                                                         143 non-null    float64\n",
      " 1   sepalwid                                                         143 non-null    float64\n",
      " 2   petallen                                                         143 non-null    float64\n",
      " 3   petalwid                                                         143 non-null    float64\n",
      " 4   irisname                                                         142 non-null    object \n",
      " 5   adapted from https://en.wikipedia.org/wiki/Iris_flower_data_set  0 non-null      float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's look at our pandas dataframe   (Aargh: that extra column!)\n",
    "#\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143 entries, 0 to 142\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   sepallen  143 non-null    float64\n",
      " 1   sepalwid  143 non-null    float64\n",
      " 2   petallen  143 non-null    float64\n",
      " 3   petalwid  143 non-null    float64\n",
      " 4   irisname  142 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 5.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's drop that last column (dropping is usually by _name_):\n",
    "#\n",
    "#   if you want a list of the column names use df.columns\n",
    "col5name = df.columns[5]  # get column name at index 5\n",
    "df_clean = df.drop(columns=[col5name])  # drop by name is typical\n",
    "df_clean.info()                         # should be happier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS is Index(['sepallen', 'sepalwid', 'petallen', 'petalwid', 'irisname'], dtype='object')\n",
      "\n",
      "COLUMNS[0] is sepallen\n",
      "\n",
      "COL_INDEX is {'sepallen': 0, 'sepalwid': 1, 'petallen': 2, 'petalwid': 3, 'irisname': 4}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's keep our column names in variables, for reference\n",
    "#\n",
    "COLUMNS = df_clean.columns            # \"list\" of columns\n",
    "print(f\"COLUMNS is {COLUMNS}\\n\")  \n",
    "  # It's a \"pandas\" list, called an Index\n",
    "  # use it just as a Python list of strings:\n",
    "print(f\"COLUMNS[0] is {COLUMNS[0]}\\n\")\n",
    "\n",
    "# let's create a dictionary to look up any column index by name\n",
    "COL_INDEX = {}\n",
    "for i, name in enumerate(COLUMNS):\n",
    "    COL_INDEX[name] = i  # using the name (as key), look up the value (i)\n",
    "print(f\"COL_INDEX is {COL_INDEX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143 entries, 0 to 142\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   sepallen  143 non-null    float64\n",
      " 1   sepalwid  143 non-null    float64\n",
      " 2   petallen  143 non-null    float64\n",
      " 3   petalwid  143 non-null    float64\n",
      " 4   irisname  142 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 5.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallen</th>\n",
       "      <th>sepalwid</th>\n",
       "      <th>petallen</th>\n",
       "      <th>petalwid</th>\n",
       "      <th>irisname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.200000e+00</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.300000e+00</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>4.2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4242.0</td>\n",
       "      <td>4.200000e+42</td>\n",
       "      <td>alieniris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>4.2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4242.0</td>\n",
       "      <td>4.200000e+42</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepallen  sepalwid  petallen      petalwid   irisname\n",
       "0         4.6       3.6       1.0  2.000000e-01     setosa\n",
       "1         4.3       3.0       1.1  1.000000e-01     setosa\n",
       "2         5.0       3.2       1.2  2.000000e-01     setosa\n",
       "3         5.8       4.0       1.2  2.000000e-01     setosa\n",
       "4         4.4       3.0       1.3  2.000000e-01     setosa\n",
       "..        ...       ...       ...           ...        ...\n",
       "138       7.7       3.8       6.7  2.200000e+00  virginica\n",
       "139       7.7       2.8       6.7  2.000000e+00  virginica\n",
       "140       7.7       2.6       6.9  2.300000e+00  virginica\n",
       "141       4.2      42.0    4242.0  4.200000e+42  alieniris\n",
       "142       4.2      42.0    4242.0  4.200000e+42        NaN\n",
       "\n",
       "[143 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# let's look at our cleaned-up dataframe...\n",
    "#\n",
    "df_clean.info()   \n",
    "#\n",
    "# notice that the non-null is _different_ for irisname!\n",
    "df_clean   # show a table! (the problem rows are the last two...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 142 entries, 0 to 141\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   sepallen  142 non-null    float64\n",
      " 1   sepalwid  142 non-null    float64\n",
      " 2   petallen  142 non-null    float64\n",
      " 3   petalwid  142 non-null    float64\n",
      " 4   irisname  142 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallen</th>\n",
       "      <th>sepalwid</th>\n",
       "      <th>petallen</th>\n",
       "      <th>petalwid</th>\n",
       "      <th>irisname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.100000e+00</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.200000e+00</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.300000e+00</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>4.2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4242.0</td>\n",
       "      <td>4.200000e+42</td>\n",
       "      <td>alieniris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepallen  sepalwid  petallen      petalwid   irisname\n",
       "0         4.6       3.6       1.0  2.000000e-01     setosa\n",
       "1         4.3       3.0       1.1  1.000000e-01     setosa\n",
       "2         5.0       3.2       1.2  2.000000e-01     setosa\n",
       "3         5.8       4.0       1.2  2.000000e-01     setosa\n",
       "4         4.4       3.0       1.3  2.000000e-01     setosa\n",
       "..        ...       ...       ...           ...        ...\n",
       "137       7.6       3.0       6.6  2.100000e+00  virginica\n",
       "138       7.7       3.8       6.7  2.200000e+00  virginica\n",
       "139       7.7       2.8       6.7  2.000000e+00  virginica\n",
       "140       7.7       2.6       6.9  2.300000e+00  virginica\n",
       "141       4.2      42.0    4242.0  4.200000e+42  alieniris\n",
       "\n",
       "[142 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# typically, after dropping columns we don't want, \n",
    "#   we drop rows with missing data (other approaches are possible, too)\n",
    "#\n",
    "df_full = df_clean.dropna()   # this removes all rows with nan items\n",
    "df_full.info()                # it's \"full\" because it has no nan items\n",
    "df_full\n",
    "#\n",
    "# notice that _all_ of the rows now have 142 non-null items\n",
    "#    also, the last row isn't real data... we'll handle it next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallen</th>\n",
       "      <th>sepalwid</th>\n",
       "      <th>petallen</th>\n",
       "      <th>petalwid</th>\n",
       "      <th>irisname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepallen  sepalwid  petallen  petalwid   irisname\n",
       "0         4.6       3.6       1.0       0.2     setosa\n",
       "1         4.3       3.0       1.1       0.1     setosa\n",
       "2         5.0       3.2       1.2       0.2     setosa\n",
       "3         5.8       4.0       1.2       0.2     setosa\n",
       "4         4.4       3.0       1.3       0.2     setosa\n",
       "..        ...       ...       ...       ...        ...\n",
       "136       7.9       3.8       6.4       2.0  virginica\n",
       "137       7.6       3.0       6.6       2.1  virginica\n",
       "138       7.7       3.8       6.7       2.2  virginica\n",
       "139       7.7       2.8       6.7       2.0  virginica\n",
       "140       7.7       2.6       6.9       2.3  virginica\n",
       "\n",
       "[141 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "# get rid of last row!\n",
    "#\n",
    "df_final = df_full.iloc[0:-1]   # not the syntax I would choose\n",
    "# careful:  don't run this again!\n",
    "print(df_final.shape)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa maps to 0\n",
      "versicolor maps to 1\n",
      "virginica maps to 2\n"
     ]
    }
   ],
   "source": [
    "# all of scikit-learn's ML routines need numbers, not strings\n",
    "#   ... even for categories/classifications (like species!)\n",
    "#   so, we will convert the flower-species to numbers:\n",
    "\n",
    "SPECIES = ['setosa','versicolor','virginica']   # int to str\n",
    "SPECIES_INDEX = {'setosa':0,'versicolor':1,'virginica':2}  # str to int\n",
    "\n",
    "def convert_species(speciesname):\n",
    "    \"\"\" return the species index (a unique integer/category) \"\"\"\n",
    "    #print(f\"converting {speciesname}...\")\n",
    "    return SPECIES_INDEX[speciesname]\n",
    "\n",
    "# Let's try it out...\n",
    "for name in SPECIES:\n",
    "    print(f\"{name} maps to {convert_species(name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-93da7aa072d5>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final['irisname'] = df_final['irisname'].apply(convert_species)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# we can \"apply\" to a whole column\n",
    "#   it may give a warning, but this is ok...\n",
    "#\n",
    "\n",
    "df_final['irisname'] = df_final['irisname'].apply(convert_species)\n",
    "\n",
    "# Don't run this twice!   Why?!  What's \"KeyError: 0\"?\n",
    "#   (for sure, you can always go back and re-establish definitions)\n",
    "\n",
    "# don't worry about the (possible)  \"SettingWithCopyWarning\" here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallen</th>\n",
       "      <th>sepalwid</th>\n",
       "      <th>petallen</th>\n",
       "      <th>petalwid</th>\n",
       "      <th>irisname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepallen  sepalwid  petallen  petalwid  irisname\n",
       "0         4.6       3.6       1.0       0.2         0\n",
       "1         4.3       3.0       1.1       0.1         0\n",
       "2         5.0       3.2       1.2       0.2         0\n",
       "3         5.8       4.0       1.2       0.2         0\n",
       "4         4.4       3.0       1.3       0.2         0\n",
       "..        ...       ...       ...       ...       ...\n",
       "136       7.9       3.8       6.4       2.0         2\n",
       "137       7.6       3.0       6.6       2.1         2\n",
       "138       7.7       3.8       6.7       2.2         2\n",
       "139       7.7       2.8       6.7       2.0         2\n",
       "140       7.7       2.6       6.9       2.3         2\n",
       "\n",
       "[141 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# let's see it!  (this is safe to run many times...)\n",
    "#\n",
    "df_final         # print(df_final.tostring())  # for _all_ rows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.6 3.6 1.  0.2 0. ]\n",
      " [4.3 3.  1.1 0.1 0. ]\n",
      " [5.  3.2 1.2 0.2 0. ]\n",
      " [5.8 4.  1.2 0.2 0. ]\n",
      " [4.4 3.  1.3 0.2 0. ]\n",
      " [4.4 3.2 1.3 0.2 0. ]\n",
      " [4.5 2.3 1.3 0.3 0. ]\n",
      " [4.7 3.2 1.3 0.2 0. ]\n",
      " [5.  3.5 1.3 0.3 0. ]\n",
      " [5.4 3.9 1.3 0.4 0. ]\n",
      " [5.5 3.5 1.3 0.2 0. ]\n",
      " [4.4 2.9 1.4 0.2 0. ]\n",
      " [4.6 3.4 1.4 0.3 0. ]\n",
      " [4.6 3.2 1.4 0.2 0. ]\n",
      " [4.8 3.  1.4 0.1 0. ]\n",
      " [4.8 3.  1.4 0.3 0. ]\n",
      " [4.9 3.  1.4 0.2 0. ]\n",
      " [5.  3.6 1.4 0.2 0. ]\n",
      " [5.  3.3 1.4 0.2 0. ]\n",
      " [5.1 3.5 1.4 0.2 0. ]\n",
      " [5.1 3.5 1.4 0.3 0. ]\n",
      " [5.2 3.4 1.4 0.2 0. ]\n",
      " [5.5 4.2 1.4 0.2 0. ]\n",
      " [4.6 3.1 1.5 0.2 0. ]\n",
      " [4.9 3.1 1.5 0.1 0. ]\n",
      " [4.9 3.1 1.5 0.1 0. ]\n",
      " [4.9 3.1 1.5 0.1 0. ]\n",
      " [5.  3.4 1.5 0.2 0. ]\n",
      " [5.1 3.8 1.5 0.3 0. ]\n",
      " [5.1 3.7 1.5 0.4 0. ]\n",
      " [5.1 3.4 1.5 0.2 0. ]\n",
      " [5.2 3.5 1.5 0.2 0. ]\n",
      " [5.3 3.7 1.5 0.2 0. ]\n",
      " [5.4 3.7 1.5 0.2 0. ]\n",
      " [5.7 4.4 1.5 0.4 0. ]\n",
      " [4.7 3.2 1.6 0.2 0. ]\n",
      " [4.8 3.4 1.6 0.2 0. ]\n",
      " [5.  3.  1.6 0.2 0. ]\n",
      " [5.  3.4 1.6 0.4 0. ]\n",
      " [5.  3.5 1.6 0.6 0. ]\n",
      " [5.1 3.8 1.6 0.2 0. ]\n",
      " [5.1 3.3 1.7 0.5 0. ]\n",
      " [5.4 3.9 1.7 0.4 0. ]\n",
      " [5.4 3.4 1.7 0.2 0. ]\n",
      " [5.7 3.8 1.7 0.3 0. ]\n",
      " [4.8 3.4 1.9 0.2 0. ]\n",
      " [5.1 3.8 1.9 0.4 0. ]\n",
      " [7.  3.2 4.7 1.4 1. ]\n",
      " [4.9 2.4 3.3 1.  1. ]\n",
      " [5.  2.3 3.3 1.  1. ]\n",
      " [5.  2.  3.5 1.  1. ]\n",
      " [5.7 2.6 3.5 1.  1. ]\n",
      " [5.6 2.9 3.6 1.3 1. ]\n",
      " [5.5 2.4 3.7 1.  1. ]\n",
      " [5.5 2.4 3.8 1.1 1. ]\n",
      " [5.2 2.7 3.9 1.4 1. ]\n",
      " [5.6 2.5 3.9 1.1 1. ]\n",
      " [5.8 2.7 3.9 1.2 1. ]\n",
      " [5.5 2.3 4.  1.3 1. ]\n",
      " [5.5 2.5 4.  1.3 1. ]\n",
      " [5.8 2.6 4.  1.2 1. ]\n",
      " [6.  2.2 4.  1.  1. ]\n",
      " [6.1 2.8 4.  1.3 1. ]\n",
      " [5.6 3.  4.1 1.3 1. ]\n",
      " [5.8 2.7 4.1 1.  1. ]\n",
      " [5.6 2.7 4.2 1.3 1. ]\n",
      " [5.7 3.  4.2 1.2 1. ]\n",
      " [5.9 3.  4.2 1.5 1. ]\n",
      " [6.4 2.9 4.3 1.3 1. ]\n",
      " [5.5 2.6 4.4 1.2 1. ]\n",
      " [6.3 2.3 4.4 1.3 1. ]\n",
      " [6.6 3.  4.4 1.4 1. ]\n",
      " [6.7 3.1 4.4 1.4 1. ]\n",
      " [5.4 3.  4.5 1.5 1. ]\n",
      " [5.6 3.  4.5 1.5 1. ]\n",
      " [5.7 2.8 4.5 1.3 1. ]\n",
      " [6.  2.9 4.5 1.5 1. ]\n",
      " [6.  3.4 4.5 1.6 1. ]\n",
      " [6.2 2.2 4.5 1.5 1. ]\n",
      " [6.4 3.2 4.5 1.5 1. ]\n",
      " [6.1 3.  4.6 1.4 1. ]\n",
      " [6.5 2.8 4.6 1.5 1. ]\n",
      " [6.6 2.9 4.6 1.3 1. ]\n",
      " [6.1 2.9 4.7 1.4 1. ]\n",
      " [6.1 2.8 4.7 1.2 1. ]\n",
      " [6.3 3.3 4.7 1.6 1. ]\n",
      " [6.7 3.1 4.7 1.5 1. ]\n",
      " [5.9 3.2 4.8 1.8 1. ]\n",
      " [6.8 2.8 4.8 1.4 1. ]\n",
      " [6.3 2.5 4.9 1.5 1. ]\n",
      " [6.9 3.1 4.9 1.5 1. ]\n",
      " [6.7 3.  5.  1.7 1. ]\n",
      " [6.  2.7 5.1 1.6 1. ]\n",
      " [4.9 2.5 4.5 1.7 2. ]\n",
      " [6.  3.  4.8 1.8 2. ]\n",
      " [6.2 2.8 4.8 1.8 2. ]\n",
      " [5.6 2.8 4.9 2.  2. ]\n",
      " [6.1 3.  4.9 1.8 2. ]\n",
      " [6.3 2.7 4.9 1.8 2. ]\n",
      " [5.7 2.5 5.  2.  2. ]\n",
      " [6.  2.2 5.  1.5 2. ]\n",
      " [6.3 2.5 5.  1.9 2. ]\n",
      " [5.8 2.8 5.1 2.4 2. ]\n",
      " [5.8 2.7 5.1 1.9 2. ]\n",
      " [5.9 3.  5.1 1.8 2. ]\n",
      " [6.3 2.8 5.1 1.5 2. ]\n",
      " [6.5 3.2 5.1 2.  2. ]\n",
      " [6.9 3.1 5.1 2.3 2. ]\n",
      " [6.5 3.  5.2 2.  2. ]\n",
      " [6.7 3.  5.2 2.3 2. ]\n",
      " [6.4 2.7 5.3 1.9 2. ]\n",
      " [6.4 3.2 5.3 2.3 2. ]\n",
      " [6.2 3.4 5.4 2.3 2. ]\n",
      " [6.9 3.1 5.4 2.1 2. ]\n",
      " [6.4 3.1 5.5 1.8 2. ]\n",
      " [6.5 3.  5.5 1.8 2. ]\n",
      " [6.8 3.  5.5 2.1 2. ]\n",
      " [6.1 2.6 5.6 1.4 2. ]\n",
      " [6.3 2.9 5.6 1.8 2. ]\n",
      " [6.3 3.4 5.6 2.4 2. ]\n",
      " [6.4 2.8 5.6 2.1 2. ]\n",
      " [6.4 2.8 5.6 2.2 2. ]\n",
      " [6.7 3.1 5.6 2.4 2. ]\n",
      " [6.7 3.3 5.7 2.1 2. ]\n",
      " [6.7 3.3 5.7 2.5 2. ]\n",
      " [6.9 3.2 5.7 2.3 2. ]\n",
      " [6.5 3.  5.8 2.2 2. ]\n",
      " [6.7 2.5 5.8 1.8 2. ]\n",
      " [7.2 3.  5.8 1.6 2. ]\n",
      " [6.8 3.2 5.9 2.3 2. ]\n",
      " [7.1 3.  5.9 2.1 2. ]\n",
      " [7.2 3.2 6.  1.8 2. ]\n",
      " [7.2 3.6 6.1 2.5 2. ]\n",
      " [7.4 2.8 6.1 1.9 2. ]\n",
      " [7.7 3.  6.1 2.3 2. ]\n",
      " [7.3 2.9 6.3 1.8 2. ]\n",
      " [7.9 3.8 6.4 2.  2. ]\n",
      " [7.6 3.  6.6 2.1 2. ]\n",
      " [7.7 3.8 6.7 2.2 2. ]\n",
      " [7.7 2.8 6.7 2.  2. ]\n",
      " [7.7 2.6 6.9 2.3 2. ]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's convert our dataframe to a numpy array, named A\n",
    "#    Our ML library, scikit-learn operates entirely on numpy arrays.\n",
    "#\n",
    "A = df_final.values    # .values gets the numpy array\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.6 3.6 1.  0.2 0. ]\n",
      " [4.3 3.  1.1 0.1 0. ]\n",
      " [5.  3.2 1.2 0.2 0. ]\n",
      " [5.8 4.  1.2 0.2 0. ]\n",
      " [4.4 3.  1.3 0.2 0. ]\n",
      " [4.4 3.2 1.3 0.2 0. ]\n",
      " [4.5 2.3 1.3 0.3 0. ]\n",
      " [4.7 3.2 1.3 0.2 0. ]\n",
      " [5.  3.5 1.3 0.3 0. ]\n",
      " [5.4 3.9 1.3 0.4 0. ]\n",
      " [5.5 3.5 1.3 0.2 0. ]\n",
      " [4.4 2.9 1.4 0.2 0. ]\n",
      " [4.6 3.4 1.4 0.3 0. ]\n",
      " [4.6 3.2 1.4 0.2 0. ]\n",
      " [4.8 3.  1.4 0.1 0. ]\n",
      " [4.8 3.  1.4 0.3 0. ]\n",
      " [4.9 3.  1.4 0.2 0. ]\n",
      " [5.  3.6 1.4 0.2 0. ]\n",
      " [5.  3.3 1.4 0.2 0. ]\n",
      " [5.1 3.5 1.4 0.2 0. ]\n",
      " [5.1 3.5 1.4 0.3 0. ]\n",
      " [5.2 3.4 1.4 0.2 0. ]\n",
      " [5.5 4.2 1.4 0.2 0. ]\n",
      " [4.6 3.1 1.5 0.2 0. ]\n",
      " [4.9 3.1 1.5 0.1 0. ]\n",
      " [4.9 3.1 1.5 0.1 0. ]\n",
      " [4.9 3.1 1.5 0.1 0. ]\n",
      " [5.  3.4 1.5 0.2 0. ]\n",
      " [5.1 3.8 1.5 0.3 0. ]\n",
      " [5.1 3.7 1.5 0.4 0. ]\n",
      " [5.1 3.4 1.5 0.2 0. ]\n",
      " [5.2 3.5 1.5 0.2 0. ]\n",
      " [5.3 3.7 1.5 0.2 0. ]\n",
      " [5.4 3.7 1.5 0.2 0. ]\n",
      " [5.7 4.4 1.5 0.4 0. ]\n",
      " [4.7 3.2 1.6 0.2 0. ]\n",
      " [4.8 3.4 1.6 0.2 0. ]\n",
      " [5.  3.  1.6 0.2 0. ]\n",
      " [5.  3.4 1.6 0.4 0. ]\n",
      " [5.  3.5 1.6 0.6 0. ]\n",
      " [5.1 3.8 1.6 0.2 0. ]\n",
      " [5.1 3.3 1.7 0.5 0. ]\n",
      " [5.4 3.9 1.7 0.4 0. ]\n",
      " [5.4 3.4 1.7 0.2 0. ]\n",
      " [5.7 3.8 1.7 0.3 0. ]\n",
      " [4.8 3.4 1.9 0.2 0. ]\n",
      " [5.1 3.8 1.9 0.4 0. ]\n",
      " [7.  3.2 4.7 1.4 1. ]\n",
      " [4.9 2.4 3.3 1.  1. ]\n",
      " [5.  2.3 3.3 1.  1. ]\n",
      " [5.  2.  3.5 1.  1. ]\n",
      " [5.7 2.6 3.5 1.  1. ]\n",
      " [5.6 2.9 3.6 1.3 1. ]\n",
      " [5.5 2.4 3.7 1.  1. ]\n",
      " [5.5 2.4 3.8 1.1 1. ]\n",
      " [5.2 2.7 3.9 1.4 1. ]\n",
      " [5.6 2.5 3.9 1.1 1. ]\n",
      " [5.8 2.7 3.9 1.2 1. ]\n",
      " [5.5 2.3 4.  1.3 1. ]\n",
      " [5.5 2.5 4.  1.3 1. ]\n",
      " [5.8 2.6 4.  1.2 1. ]\n",
      " [6.  2.2 4.  1.  1. ]\n",
      " [6.1 2.8 4.  1.3 1. ]\n",
      " [5.6 3.  4.1 1.3 1. ]\n",
      " [5.8 2.7 4.1 1.  1. ]\n",
      " [5.6 2.7 4.2 1.3 1. ]\n",
      " [5.7 3.  4.2 1.2 1. ]\n",
      " [5.9 3.  4.2 1.5 1. ]\n",
      " [6.4 2.9 4.3 1.3 1. ]\n",
      " [5.5 2.6 4.4 1.2 1. ]\n",
      " [6.3 2.3 4.4 1.3 1. ]\n",
      " [6.6 3.  4.4 1.4 1. ]\n",
      " [6.7 3.1 4.4 1.4 1. ]\n",
      " [5.4 3.  4.5 1.5 1. ]\n",
      " [5.6 3.  4.5 1.5 1. ]\n",
      " [5.7 2.8 4.5 1.3 1. ]\n",
      " [6.  2.9 4.5 1.5 1. ]\n",
      " [6.  3.4 4.5 1.6 1. ]\n",
      " [6.2 2.2 4.5 1.5 1. ]\n",
      " [6.4 3.2 4.5 1.5 1. ]\n",
      " [6.1 3.  4.6 1.4 1. ]\n",
      " [6.5 2.8 4.6 1.5 1. ]\n",
      " [6.6 2.9 4.6 1.3 1. ]\n",
      " [6.1 2.9 4.7 1.4 1. ]\n",
      " [6.1 2.8 4.7 1.2 1. ]\n",
      " [6.3 3.3 4.7 1.6 1. ]\n",
      " [6.7 3.1 4.7 1.5 1. ]\n",
      " [5.9 3.2 4.8 1.8 1. ]\n",
      " [6.8 2.8 4.8 1.4 1. ]\n",
      " [6.3 2.5 4.9 1.5 1. ]\n",
      " [6.9 3.1 4.9 1.5 1. ]\n",
      " [6.7 3.  5.  1.7 1. ]\n",
      " [6.  2.7 5.1 1.6 1. ]\n",
      " [4.9 2.5 4.5 1.7 2. ]\n",
      " [6.  3.  4.8 1.8 2. ]\n",
      " [6.2 2.8 4.8 1.8 2. ]\n",
      " [5.6 2.8 4.9 2.  2. ]\n",
      " [6.1 3.  4.9 1.8 2. ]\n",
      " [6.3 2.7 4.9 1.8 2. ]\n",
      " [5.7 2.5 5.  2.  2. ]\n",
      " [6.  2.2 5.  1.5 2. ]\n",
      " [6.3 2.5 5.  1.9 2. ]\n",
      " [5.8 2.8 5.1 2.4 2. ]\n",
      " [5.8 2.7 5.1 1.9 2. ]\n",
      " [5.9 3.  5.1 1.8 2. ]\n",
      " [6.3 2.8 5.1 1.5 2. ]\n",
      " [6.5 3.2 5.1 2.  2. ]\n",
      " [6.9 3.1 5.1 2.3 2. ]\n",
      " [6.5 3.  5.2 2.  2. ]\n",
      " [6.7 3.  5.2 2.3 2. ]\n",
      " [6.4 2.7 5.3 1.9 2. ]\n",
      " [6.4 3.2 5.3 2.3 2. ]\n",
      " [6.2 3.4 5.4 2.3 2. ]\n",
      " [6.9 3.1 5.4 2.1 2. ]\n",
      " [6.4 3.1 5.5 1.8 2. ]\n",
      " [6.5 3.  5.5 1.8 2. ]\n",
      " [6.8 3.  5.5 2.1 2. ]\n",
      " [6.1 2.6 5.6 1.4 2. ]\n",
      " [6.3 2.9 5.6 1.8 2. ]\n",
      " [6.3 3.4 5.6 2.4 2. ]\n",
      " [6.4 2.8 5.6 2.1 2. ]\n",
      " [6.4 2.8 5.6 2.2 2. ]\n",
      " [6.7 3.1 5.6 2.4 2. ]\n",
      " [6.7 3.3 5.7 2.1 2. ]\n",
      " [6.7 3.3 5.7 2.5 2. ]\n",
      " [6.9 3.2 5.7 2.3 2. ]\n",
      " [6.5 3.  5.8 2.2 2. ]\n",
      " [6.7 2.5 5.8 1.8 2. ]\n",
      " [7.2 3.  5.8 1.6 2. ]\n",
      " [6.8 3.2 5.9 2.3 2. ]\n",
      " [7.1 3.  5.9 2.1 2. ]\n",
      " [7.2 3.2 6.  1.8 2. ]\n",
      " [7.2 3.6 6.1 2.5 2. ]\n",
      " [7.4 2.8 6.1 1.9 2. ]\n",
      " [7.7 3.  6.1 2.3 2. ]\n",
      " [7.3 2.9 6.3 1.8 2. ]\n",
      " [7.9 3.8 6.4 2.  2. ]\n",
      " [7.6 3.  6.6 2.1 2. ]\n",
      " [7.7 3.8 6.7 2.2 2. ]\n",
      " [7.7 2.8 6.7 2.  2. ]\n",
      " [7.7 2.6 6.9 2.3 2. ]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's make sure it's all floating-point, so we can multiply and divide\n",
    "#\n",
    "A = A.astype('float64')  # so many:  www.tutorialspoint.com/numpy/numpy_data_types.htm\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataset has 141 rows and 5 cols\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# nice to have NUM_ROWS and NUM_COLS around\n",
    "#\n",
    "NUM_ROWS, NUM_COLS = A.shape\n",
    "print(f\"\\nThe dataset has {NUM_ROWS} rows and {NUM_COLS} cols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flower #132 is [7.2 3.6 6.1 2.5 2. ]\n",
      "  Its sepallen is 7.2\n",
      "  Its sepalwid is 3.6\n",
      "  Its petallen is 6.1\n",
      "  Its petalwid is 2.5\n",
      "  Its irisname is virginica (2)\n"
     ]
    }
   ],
   "source": [
    "# let's use all of our variables, to reinforce names...\n",
    "\n",
    "# choose a row index, n:\n",
    "n = 132\n",
    "print(f\"flower #{n} is {A[n]}\")\n",
    "\n",
    "for i in range(len(COLUMNS)):\n",
    "    colname = COLUMNS[i]\n",
    "    if colname != 'irisname':\n",
    "        print(f\"  Its {colname} is {A[n][i]}\")\n",
    "    else:\n",
    "        species_num = int(A[n][i])\n",
    "        species = SPECIES[species_num]\n",
    "        print(f\"  Its {colname} is {species} ({species_num})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I predict versicolor (1) from Features [4.6, 3.6, 3.0, 1.2]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# We don't have to use scikit-learn to implement n.n.!\n",
    "#\n",
    "\n",
    "#\n",
    "# data-driven predictive model (1-nearest-neighbor)\n",
    "#\n",
    "dist = np.linalg.norm  # built in to numpy\n",
    "NUM_ROWS, NUM_COLS = A.shape  # data size\n",
    "\n",
    "def predictive_model( Features ):\n",
    "    \"\"\" input: a list of four features \n",
    "                [ sepallen, sepalwid, petallen, petalwid ]\n",
    "        output: the predicted species of iris, from\n",
    "                  setosa (0), versicolor (1), virginica (2)\n",
    "    \"\"\"\n",
    "    our_features = np.asarray(Features)   # make a numpy array\n",
    "    \n",
    "    closest_flower   = A[0]\n",
    "    closest_features = A[0,0:4]         \n",
    "    closest_distance = dist(our_features-closest_features)\n",
    "    \n",
    "    for i in range(NUM_ROWS):\n",
    "        current_flower   = A[i]\n",
    "        current_features = A[i,0:4] \n",
    "        current_distance = dist(our_features-current_features)\n",
    "        \n",
    "        if current_distance < closest_distance:\n",
    "            closest_distance = current_distance  # remember closest!\n",
    "            closest_flower = current_flower\n",
    "    \n",
    "    # done comparing with every flower in the dataset\n",
    "    predicted_species = int(round(closest_flower[4]))\n",
    "    name = SPECIES[predicted_species]\n",
    "    return f\"{name} ({predicted_species})\"\n",
    "    \n",
    "#\n",
    "# Try it!\n",
    "# \n",
    "# Features = eval(input(\"Enter new Features: \"))\n",
    "#\n",
    "Features = [ 4.6, 3.6, 3.0, 1.2 ] \n",
    "result = predictive_model( Features )\n",
    "print(f\"I predict {result} from Features {Features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# but, we don't have to write our own ... because\n",
    "#\n",
    "#     we want knn for any k!\n",
    "#     we want an already-debugged algorithm!\n",
    "#     we want to ask iris q'ns instead of implementation ones... (?)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Start of data definitions +++\n",
      "\n",
      "X_all (just features) is \n",
      " [[4.6 3.6 1.  0.2]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [7.7 2.6 6.9 2.3]]\n",
      "y_all (just labels)   is \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(\"+++ Start of data definitions +++\\n\")\n",
    "\n",
    "X_all = A[:,0:4]  # X (features) ... is all rows, columns 0, 1, 2, 3\n",
    "y_all = A[:,4]    # y (labels) ... is all rows, column 4 only\n",
    "\n",
    "print(f\"X_all (just features) is \\n {X_all}\")\n",
    "print(f\"y_all (just labels)   is \\n {y_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighting sepallen by 1.0\n",
      "Weighting sepalwid by 1.0\n",
      "Weighting petallen by 1.0\n",
      "Weighting petalwid by 1.0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# we can re-weight different features here...\n",
    "#\n",
    "\n",
    "COL_WEIGHT = {              # could be called Feature weight...\n",
    "    'sepallen':1.0,\n",
    "    'sepalwid':1.0,\n",
    "    'petallen':1.0,\n",
    "    'petalwid':1.0,\n",
    "}\n",
    "\n",
    "for colname in COL_WEIGHT:\n",
    "    i = COL_INDEX[colname]    # get the column index, i, of the colname\n",
    "    weight = COL_WEIGHT[colname]  # from the dictionary above\n",
    "    print(\"Weighting\", colname, \"by\", weight)   \n",
    "    # weighting == \"multiplying\"\n",
    "    X_all[:,i] *= weight   # multiply by the weight to give this column (\"feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.2 2.2 4.5 1.5]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [6.7 3.  5.  1.7]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.  2.  3.5 1. ]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.  3.  1.6 0.2]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [5.1 3.3 1.7 0.5]]\n",
      "[1. 1. 1. 2. 0. 2. 2. 0. 1. 1. 2. 1. 0. 0. 1. 1. 1. 0. 0. 2. 0. 0. 2. 2.\n",
      " 0. 2. 2. 2. 2. 0. 2. 2. 2. 1. 1. 1. 1. 0. 1. 1. 0. 2. 1. 2. 2. 2. 2. 1.\n",
      " 0. 0. 1. 1. 2. 2. 0. 2. 1. 2. 1. 1. 2. 1. 0. 2. 2. 0. 0. 0. 1. 2. 2. 2.\n",
      " 2. 2. 1. 1. 0. 0. 0. 1. 0. 1. 0. 2. 0. 2. 0. 0. 1. 0. 1. 2. 0. 2. 2. 1.\n",
      " 1. 0. 1. 0. 0. 0. 2. 0. 1. 2. 2. 2. 1. 2. 0. 1. 2. 1. 0. 0. 0. 0. 1. 0.\n",
      " 0. 2. 1. 0. 2. 0. 1. 2. 0. 0. 1. 1. 2. 1. 2. 1. 1. 0. 1. 2. 0.]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# we scramble the data, to give a different TRAIN/TEST split each time...\n",
    "# \n",
    "indices = np.random.permutation(len(y_all))  # indices is a permutation-list\n",
    "\n",
    "# we scramble both X and y, necessarily with the same permutation\n",
    "X_labeled = X_all[indices]              # we apply the _same_ permutation to each!\n",
    "y_labeled = y_all[indices]              # again...\n",
    "print(X_labeled)\n",
    "print(y_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 113 rows;  testing with 28 rows\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# We next separate into test data and training data ... \n",
    "#    + We will train on the training data...\n",
    "#    + We will _not_ look at the testing data to build the model\n",
    "#\n",
    "# Then, afterward, we will test on the testing data -- and see how well we do!\n",
    "#\n",
    "\n",
    "#\n",
    "# a common convention:  train on 80%, test on 20%    Let's define the TEST_PERCENT\n",
    "#\n",
    "NUM_ROWS = X_labeled.shape[0]     # the number of labeled rows\n",
    "TEST_PERCENT = 0.20\n",
    "TEST_SIZE = int(TEST_PERCENT*NUM_ROWS)   # no harm in rounding down\n",
    "\n",
    "X_test = X_labeled[:TEST_SIZE]    # first section are for testing\n",
    "y_test = y_labeled[:TEST_SIZE]\n",
    "\n",
    "X_train = X_labeled[TEST_SIZE:]   # all the rest are for training\n",
    "y_train = y_labeled[TEST_SIZE:]\n",
    "\n",
    "print(f\"training with {len(y_train)} rows;  testing with {len(y_test)} rows\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and trained a knn classifier with k = 84\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# +++ This is the \"Model-building and Model-training Cell\"\n",
    "#       \n",
    "# Create a kNN model and train it! \n",
    "#\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k = 84   # we don't know what k to use, so we guess!  (this will _not_ be a good value)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=k)       # here, k is the \"k\" in kNN\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "knn_model.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(\"Created and trained a knn classifier with k =\", k)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [2. 1. 1. 2. 0. 2. 2. 0. 1. 1. 2. 1. 0. 0. 1. 2. 2. 0. 0. 2. 0. 0. 2. 2.\n",
      " 0. 2. 1. 2.]\n",
      "Actual  labels  : [1. 1. 1. 2. 0. 2. 2. 0. 1. 1. 2. 1. 0. 0. 1. 1. 1. 0. 0. 2. 0. 0. 2. 2.\n",
      " 0. 2. 2. 2.]\n",
      "\n",
      "Results on test set:  24 correct out of 28 total.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# +++ This is the \"Model-testing Cell\"\n",
    "#\n",
    "# Now, let's see how well we did on our \"held-out data\" (the testing data)\n",
    "#\n",
    "\n",
    "# We run our test set!\n",
    "predicted_labels = knn_model.predict(X_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual  labels  :\", actual_labels)\n",
    "\n",
    "# And, some overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Let's print these more helpfully, in a vertical table\n",
    "#\n",
    "\n",
    "def compare_labels(predicted_labels, actual_labels):\n",
    "    \"\"\" a more neatly formatted comparison \"\"\"\n",
    "    NUM_LABELS = len(predicted_labels)\n",
    "    num_correct = 0\n",
    "    \n",
    "    for i in range(NUM_LABELS):\n",
    "        p = int(round(predicted_labels[i]))         # round protects from fp error \n",
    "        a = int(round(actual_labels[i]))\n",
    "        result = \"incorrect\"\n",
    "        if p == a:  # if they match,\n",
    "            result = \"\"       # no longer incorrect\n",
    "            num_correct += 1  # and we count a match!\n",
    "\n",
    "        print(f\"row {i:>3d} : {SPECIES[p]:>12s} {SPECIES[a]:<12s}   {result}\")   \n",
    "\n",
    "    print()\n",
    "    print(\"Correct:\", num_correct, \"out of\", NUM_LABELS)\n",
    "    return num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row   0 :    virginica versicolor     incorrect\n",
      "row   1 :   versicolor versicolor     \n",
      "row   2 :   versicolor versicolor     \n",
      "row   3 :    virginica virginica      \n",
      "row   4 :       setosa setosa         \n",
      "row   5 :    virginica virginica      \n",
      "row   6 :    virginica virginica      \n",
      "row   7 :       setosa setosa         \n",
      "row   8 :   versicolor versicolor     \n",
      "row   9 :   versicolor versicolor     \n",
      "row  10 :    virginica virginica      \n",
      "row  11 :   versicolor versicolor     \n",
      "row  12 :       setosa setosa         \n",
      "row  13 :       setosa setosa         \n",
      "row  14 :   versicolor versicolor     \n",
      "row  15 :    virginica versicolor     incorrect\n",
      "row  16 :    virginica versicolor     incorrect\n",
      "row  17 :       setosa setosa         \n",
      "row  18 :       setosa setosa         \n",
      "row  19 :    virginica virginica      \n",
      "row  20 :       setosa setosa         \n",
      "row  21 :       setosa setosa         \n",
      "row  22 :    virginica virginica      \n",
      "row  23 :    virginica virginica      \n",
      "row  24 :       setosa setosa         \n",
      "row  25 :    virginica virginica      \n",
      "row  26 :   versicolor virginica      incorrect\n",
      "row  27 :    virginica virginica      \n",
      "\n",
      "Correct: 24 out of 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# let's try it out!\n",
    "#\n",
    "\n",
    "compare_labels(predicted_labels,actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I predict virginica (2) from Features [6.7, 3.3, 5.7, 2.1]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Ok!  We have our knn model, we could just use it...\n",
    "#\n",
    "\n",
    "#\n",
    "# data-driven predictive model (k-nearest-neighbor), using scikit-learn\n",
    "#\n",
    "\n",
    "def predictive_model( Features ):\n",
    "    \"\"\" input: a list of four features \n",
    "                [ sepallen, sepalwid, petallen, petalwid ]\n",
    "        output: the predicted species of iris, from\n",
    "                  setosa (0), versicolor (1), virginica (2)\n",
    "    \"\"\"\n",
    "    our_features = np.asarray([Features])                 # extra brackets needed\n",
    "    predicted_species = knn_model.predict(our_features)\n",
    "    \n",
    "    predicted_species = int(round(predicted_species[0]))  # unpack one element\n",
    "    name = SPECIES[predicted_species]\n",
    "    return f\"{name} ({predicted_species})\"\n",
    "    \n",
    "#\n",
    "# Try it!\n",
    "# \n",
    "# Features = eval(input(\"Enter new Features: \"))\n",
    "#\n",
    "Features = [6.7,3.3,5.7,2.1]  # [5.8,2.7,4.1,1.0] [4.6,3.6,3.0,2.2] [6.7,3.3,5.7,2.1]\n",
    "result = predictive_model( Features )\n",
    "print(f\"I predict {result} from Features {Features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Except, we didn't really explore whether this was the BEST model we could build!\n",
    "#\n",
    "#\n",
    "# We used k = 84  (a neighborhood size of 84 flowers)\n",
    "# In a dataset of only 140ish flowers, with three species, this seems like a bad idea!\n",
    "#\n",
    "# Perhaps we should try ALL the neighborhood sizes in their own TRAIN/TEST split\n",
    "# and see which neighborhood size works the best, for irises, at least...\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  1  cv accuracy:  0.9466\n",
      "k:  2  cv accuracy:  0.9379\n",
      "k:  3  cv accuracy:  0.9557\n",
      "k:  4  cv accuracy:  0.9557\n",
      "k:  5  cv accuracy:  0.9648\n",
      "k:  6  cv accuracy:  0.9561\n",
      "k:  7  cv accuracy:  0.9561\n",
      "k:  8  cv accuracy:  0.9379\n",
      "k:  9  cv accuracy:  0.9470\n",
      "k: 10  cv accuracy:  0.9470\n",
      "k: 11  cv accuracy:  0.9648\n",
      "k: 12  cv accuracy:  0.9379\n",
      "k: 13  cv accuracy:  0.9466\n",
      "k: 14  cv accuracy:  0.9379\n",
      "k: 15  cv accuracy:  0.9379\n",
      "k: 16  cv accuracy:  0.9379\n",
      "k: 17  cv accuracy:  0.9466\n",
      "k: 18  cv accuracy:  0.9466\n",
      "k: 19  cv accuracy:  0.9466\n",
      "k: 20  cv accuracy:  0.9289\n",
      "k: 21  cv accuracy:  0.9289\n",
      "k: 22  cv accuracy:  0.9289\n",
      "k: 23  cv accuracy:  0.9379\n",
      "k: 24  cv accuracy:  0.9379\n",
      "k: 25  cv accuracy:  0.9379\n",
      "k: 26  cv accuracy:  0.9285\n",
      "k: 27  cv accuracy:  0.9379\n",
      "k: 28  cv accuracy:  0.9285\n",
      "k: 29  cv accuracy:  0.9375\n",
      "k: 30  cv accuracy:  0.9289\n",
      "k: 31  cv accuracy:  0.9375\n",
      "k: 32  cv accuracy:  0.9375\n",
      "k: 33  cv accuracy:  0.9289\n",
      "k: 34  cv accuracy:  0.9198\n",
      "k: 35  cv accuracy:  0.9198\n",
      "k: 36  cv accuracy:  0.9111\n",
      "k: 37  cv accuracy:  0.9202\n",
      "k: 38  cv accuracy:  0.9111\n",
      "k: 39  cv accuracy:  0.9202\n",
      "k: 40  cv accuracy:  0.9024\n",
      "k: 41  cv accuracy:  0.9111\n",
      "k: 42  cv accuracy:  0.9024\n",
      "k: 43  cv accuracy:  0.9111\n",
      "k: 44  cv accuracy:  0.9024\n",
      "k: 45  cv accuracy:  0.9111\n",
      "k: 46  cv accuracy:  0.9024\n",
      "k: 47  cv accuracy:  0.9111\n",
      "k: 48  cv accuracy:  0.9024\n",
      "k: 49  cv accuracy:  0.9111\n",
      "k: 50  cv accuracy:  0.9111\n",
      "k: 51  cv accuracy:  0.9024\n",
      "k: 52  cv accuracy:  0.8937\n",
      "k: 53  cv accuracy:  0.8850\n",
      "k: 54  cv accuracy:  0.8933\n",
      "k: 55  cv accuracy:  0.8846\n",
      "k: 56  cv accuracy:  0.8933\n",
      "k: 57  cv accuracy:  0.9024\n",
      "k: 58  cv accuracy:  0.8933\n",
      "k: 59  cv accuracy:  0.8585\n",
      "k: 60  cv accuracy:  0.8150\n",
      "k: 61  cv accuracy:  0.8059\n",
      "k: 62  cv accuracy:  0.8059\n",
      "k: 63  cv accuracy:  0.8059\n",
      "k: 64  cv accuracy:  0.8059\n",
      "k: 65  cv accuracy:  0.7968\n",
      "k: 66  cv accuracy:  0.7968\n",
      "k: 67  cv accuracy:  0.7881\n",
      "k: 68  cv accuracy:  0.7881\n",
      "k: 69  cv accuracy:  0.7881\n",
      "k: 70  cv accuracy:  0.7881\n",
      "k: 71  cv accuracy:  0.7794\n",
      "k: 72  cv accuracy:  0.7794\n",
      "k: 73  cv accuracy:  0.7794\n",
      "k: 74  cv accuracy:  0.7704\n",
      "k: 75  cv accuracy:  0.7613\n",
      "k: 76  cv accuracy:  0.7613\n",
      "k: 77  cv accuracy:  0.7613\n",
      "k: 78  cv accuracy:  0.7526\n",
      "k: 79  cv accuracy:  0.7526\n",
      "k: 80  cv accuracy:  0.7526\n",
      "k: 81  cv accuracy:  0.7526\n",
      "k: 82  cv accuracy:  0.7439\n",
      "k: 83  cv accuracy:  0.7439\n",
      "k: 84  cv accuracy:  0.7352\n",
      "best_k = 5   yields the highest average cv accuracy.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# to do this, we use \"cross validation\"\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#\n",
    "# cross-validation splits the training set into two pieces:\n",
    "#   + model-building and model-validation. We'll use \"build\" and \"validate\"\n",
    "#\n",
    "best_k = 0\n",
    "best_accuracy = 0\n",
    "for k in range(1,85):\n",
    "    knn_cv_model = KNeighborsClassifier(n_neighbors=k)   # build knn_model for every k!\n",
    "    cv_scores = cross_val_score( knn_cv_model, X_train, y_train, cv=5 )  # 5 means 80/20 split\n",
    "    # print(cv_scores)  # just to see the five scores... \n",
    "    average_cv_accuracy = cv_scores.mean()  # mean() is numpy's built-in average function \n",
    "    if average_cv_accuracy > best_accuracy:\n",
    "        best_k = k\n",
    "        best_accuracy = average_cv_accuracy\n",
    "    \n",
    "    print(f\"k: {k:2d}  cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "\n",
    "    \n",
    "    \n",
    "# assign best value of k to best_k\n",
    "# you'll need to use the loop above to find and remember the real best_k\n",
    "\n",
    "print(f\"best_k = {best_k}   yields the highest average cv accuracy.\")  # print the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created + trained a knn classifier, now tuned with a (best) k of 5\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Now, we re-create and re-run the  \"Model-building and -training Cell\"\n",
    "#\n",
    "# Now, using best_k instead of the original, randomly-guessed value    How does it do?!\n",
    "#\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model_tuned = KNeighborsClassifier(n_neighbors=best_k)   # here, we use the best_k\n",
    "\n",
    "# we train the model (one line!)\n",
    "knn_model_tuned.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(f\"Created + trained a knn classifier, now tuned with a (best) k of {best_k}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1. 1. 1. 2. 0. 2. 2. 0. 1. 1. 2. 1. 0. 0. 1. 1. 1. 0. 0. 2. 0. 0. 2. 2.\n",
      " 0. 2. 1. 2.]\n",
      "Actual labels: [1. 1. 1. 2. 0. 2. 2. 0. 1. 1. 2. 1. 0. 0. 1. 1. 1. 0. 0. 2. 0. 0. 2. 2.\n",
      " 0. 2. 2. 2.]\n",
      "\n",
      "row   0 :   versicolor versicolor     \n",
      "row   1 :   versicolor versicolor     \n",
      "row   2 :   versicolor versicolor     \n",
      "row   3 :    virginica virginica      \n",
      "row   4 :       setosa setosa         \n",
      "row   5 :    virginica virginica      \n",
      "row   6 :    virginica virginica      \n",
      "row   7 :       setosa setosa         \n",
      "row   8 :   versicolor versicolor     \n",
      "row   9 :   versicolor versicolor     \n",
      "row  10 :    virginica virginica      \n",
      "row  11 :   versicolor versicolor     \n",
      "row  12 :       setosa setosa         \n",
      "row  13 :       setosa setosa         \n",
      "row  14 :   versicolor versicolor     \n",
      "row  15 :   versicolor versicolor     \n",
      "row  16 :   versicolor versicolor     \n",
      "row  17 :       setosa setosa         \n",
      "row  18 :       setosa setosa         \n",
      "row  19 :    virginica virginica      \n",
      "row  20 :       setosa setosa         \n",
      "row  21 :       setosa setosa         \n",
      "row  22 :    virginica virginica      \n",
      "row  23 :    virginica virginica      \n",
      "row  24 :       setosa setosa         \n",
      "row  25 :    virginica virginica      \n",
      "row  26 :   versicolor virginica      incorrect\n",
      "row  27 :    virginica virginica      \n",
      "\n",
      "Correct: 27 out of 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Re-create and re-run the  \"Model-testing Cell\"     How does it do with best_k?!\n",
    "#\n",
    "predicted_labels = knn_model_tuned.predict(X_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)\n",
    "print()\n",
    "# and, we'll print our nicer table...\n",
    "compare_labels(predicted_labels,actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created + trained a 'final' knn classifier, with a (best) k of 5\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Ok!  We have tuned knn to use the \"best\" value of k...\n",
    "#\n",
    "# And, we should really use ALL available data to train our final predictive model:\n",
    "#\n",
    "\n",
    "knn_model_final = KNeighborsClassifier(n_neighbors=best_k)   # here, we use the best_k\n",
    "knn_model_final.fit(X_all, y_all)                              # yay!  trained!\n",
    "print(f\"Created + trained a 'final' knn classifier, with a (best) k of {best_k}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I predict virginica (2) from Features [6.7, 3.3, 5.7, 2.1]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# final predictive model (k-nearest-neighbor), with tuned k + ALL data incorporated\n",
    "#\n",
    "\n",
    "def predictive_model( Features ):\n",
    "    \"\"\" input: a list of four features \n",
    "                [ sepallen, sepalwid, petallen, petalwid ]\n",
    "        output: the predicted species of iris, from\n",
    "                  setosa (0), versicolor (1), virginica (2)\n",
    "    \"\"\"\n",
    "    our_features = np.asarray([Features])                 # extra brackets needed\n",
    "    predicted_species = knn_model_final.predict(our_features)\n",
    "    \n",
    "    predicted_species = int(round(predicted_species[0]))  # unpack one element\n",
    "    name = SPECIES[predicted_species]\n",
    "    return f\"{name} ({predicted_species})\"\n",
    "    \n",
    "#\n",
    "# Try it!\n",
    "# \n",
    "# Features = eval(input(\"Enter new Features: \"))\n",
    "#\n",
    "Features = [6.7,3.3,5.7,2.1]  # [5.8,2.7,4.1,1.0] [4.6,3.6,3.0,2.2] [6.7,3.3,5.7,2.1]\n",
    "result = predictive_model( Features )\n",
    "print(f\"I predict {result} from Features {Features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I predict versicolor (1) from Features [5.7, 2.8, 4.1, 1.3]\n",
      "I predict virginica (2) from Features [6.3, 3.3, 6.0, 2.5]\n",
      "I predict versicolor (1) from Features [6.2, 2.9, 4.3, 1.3]\n",
      "I predict versicolor (1) from Features [5.1, 2.5, 3.0, 1.1]\n",
      "I predict setosa (0) from Features [5.4, 3.4, 1.5, 0.4]\n",
      "I predict setosa (0) from Features [5.2, 4.1, 1.5, 0.1]\n",
      "I predict virginica (2) from Features [5.8, 2.7, 5.1, 1.9]\n",
      "I predict versicolor (1) from Features [5.7, 2.9, 4.2, 1.3]\n",
      "I predict setosa (0) from Features [4.8, 3.1, 1.6, 0.2]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# try it on new data!  (grab it from the problem statement)\n",
    "#\n",
    "#\n",
    "# TO DO for hw4pr1:\n",
    "#       write a loop that will handle _multiple_ new flowers and predict their species...\n",
    "#\n",
    "\n",
    "LoF = [[5.7, 2.8, 4.1, 1.3],\n",
    "[6.3, 3.3, 6.0, 2.5 ],\n",
    "[6.2, 2.9, 4.3, 1.3 ],\n",
    "[5.1, 2.5, 3.0, 1.1 ],\n",
    "[5.4, 3.4, 1.5, 0.4 ],\n",
    "[5.2, 4.1, 1.5, 0.1 ],\n",
    "[5.8, 2.7, 5.1, 1.9 ],\n",
    "[5.7, 2.9, 4.2, 1.3 ],\n",
    "[4.8, 3.1, 1.6, 0.2 ]]\n",
    "\n",
    "for x in LoF:\n",
    "    result = predictive_model(x)\n",
    "    print(f\"I predict {result} from Features {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Be sure your results from trying this on the unknown data are here - or above!\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# That's it!  Welcome to the world of model-building workflows!!    \n",
    "#\n",
    "#             Our prediction?  We'll be back for more ML! \n",
    "#\n",
    "\n",
    "#\n",
    "# In fact, the rest of the hw is to run more ML workflows:   Digits, Titanic, Housing, ...\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
